
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'swr-bayes-in-one';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="My sample book - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="README.html">
                    models-of-the-mind-notebooks
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="00_python-jupyter-overview.html">Models of the Mind, 2024</a></li>



<li class="toctree-l1"><a class="reference internal" href="01_game-of-life.html">Conwayâ€™s â€œGame of Lifeâ€</a></li>

<li class="toctree-l1"><a class="reference internal" href="02a_math-probability-matching.html"><font color="red">LAB REPORT</font></a></li>


<li class="toctree-l1"><a class="reference internal" href="02b_math-probability-matching.html">PROBABILITY MATCHING, PART 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_agent-probability-matching.html">PROBABILITY MATCHING, PART 3</a></li>




<li class="toctree-l1"><a class="reference internal" href="04_probability-review.html">Preliminaries: Understanding Logical Symbols in Probability</a></li>








<li class="toctree-l1"><a class="reference internal" href="05_bayes-theorem.html">Introduction to Bayesâ€™ theorem</a></li>








<li class="toctree-l1"><a class="reference internal" href="05_bayes-theorem-rev.html">Introduction to Bayesâ€™ theorem</a></li>








<li class="toctree-l1"><a class="reference internal" href="06_pseudo-swr-analysis.html">More on mathematical models: Statistical models</a></li>


<li class="toctree-l1"><a class="reference internal" href="07_swr-bayes-004.html">Introduction</a></li>





<li class="toctree-l1"><a class="reference internal" href="08_trace-swr.html">Implementations of the TRACE model</a></li>


<li class="toctree-l1"><a class="reference internal" href="10_netsci-01.html">Network Science Overview</a></li>








<li class="toctree-l1"><a class="reference internal" href="11_nnets-01-linear-functions-and-bias.html">Neural networks, Part 1: Linear logic functions as networks</a></li>


<li class="toctree-l1"><a class="reference internal" href="12_nnets-02-training-linear-networks.html">Neural networks, Part 2 â€“ training networks</a></li>

<li class="toctree-l1"><a class="reference internal" href="13_nnets-03-learning-xor.html">Neural networks, Part 3 â€“ training networks for non-linearly separable mappings</a></li>



<li class="toctree-l1"><a class="reference internal" href="14_nnets-04-srn-statlearn.html">Neural networks, Part 4</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fswr-bayes-in-one.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/swr-bayes-in-one.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1><no title></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="simple visible nav section-nav flex-column">
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">leaves_list</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="k">def</span> <span class="nf">get_phoneme_prob_at_position</span><span class="p">(</span><span class="n">phoneme</span><span class="p">,</span> <span class="n">normalized_cosine_sim_df</span><span class="p">,</span> <span class="n">phoneme_prob_dict</span><span class="p">):</span>
<span class="w">    </span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the bottom-up probability for a phoneme at a given position.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">        phoneme (str): The current phoneme.</span>
<span class="sd">        normalized_cosine_sim_df (DataFrame): The DataFrame containing the normalized cosine similarities between phonemes.</span>
<span class="sd">        phoneme_prob_dict (dict): The dictionary containing the probabilities of each phoneme.</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        pd.Series: The probabilities of each phoneme at the current position.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">evidence_distribution</span> <span class="o">=</span> <span class="n">normalized_cosine_sim_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">phoneme</span><span class="p">]</span>
    
    <span class="c1"># Instead of multiplying the whole Series with a dictionary, use map for element-wise multiplication</span>
    <span class="n">evidence_distribution</span> <span class="o">=</span> <span class="n">evidence_distribution</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="n">phoneme_prob_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># normalize (back to probabilities) and return</span>
    <span class="k">return</span> <span class="n">evidence_distribution</span> <span class="o">/</span> <span class="n">evidence_distribution</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">sim_bayes_new</span><span class="p">(</span><span class="n">target_word</span><span class="p">,</span> <span class="n">lexicon_df</span><span class="p">,</span> <span class="n">normalized_cosine_sim_df</span><span class="p">,</span> <span class="n">phoneme_prob_dict</span><span class="p">,</span> <span class="n">topX</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simulate word recognition based on Bayesian inference.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">        target_word (str): The target word to recognize.</span>
<span class="sd">        lexicon_df (DataFrame): The DataFrame containing the lexicon.</span>
<span class="sd">        normalized_cosine_sim_df (DataFrame): The DataFrame containing the normalized cosine similarities between phonemes.</span>
<span class="sd">        phoneme_prob_dict (dict): The dictionary containing the probabilities of each phoneme.</span>
<span class="sd">        topX: how many words to retain in the dictionary based on peak evidence values</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        posterior_word_df, posterior_phon_df: 2 dataframes with word and phoneme probabilities by position</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Initialize</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;--- Starting simulation of word </span><span class="si">{</span><span class="n">target_word</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="c1"># let&#39;s get the phonemes for the target word</span>
    <span class="c1"># this just pulls the Pronunciation for the target word</span>
    <span class="n">target_pronunciation</span> <span class="o">=</span> <span class="n">lexicon_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">lexicon_df</span><span class="p">[</span><span class="s1">&#39;Item&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">target_word</span><span class="p">,</span> <span class="s1">&#39;Pronunciation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">target_phonemes</span> <span class="o">=</span> <span class="n">target_pronunciation</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">result_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">phoneme_prob_list</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># New list to store phoneme probabilities</span>

    <span class="c1"># Print the elapsed time -- nothing essential, just updating the user</span>
    <span class="c1"># part1 = time.time()</span>
    <span class="c1"># elapsed_time = part1 - start_time</span>
    <span class="c1"># print(f&quot;  Part 1a: {elapsed_time:.6f} seconds&quot;)</span>
    
    <span class="c1"># this is wasteful to compute every time, but it takes very little time</span>
    <span class="c1"># we need the sum of all lfrq values to convert to probabilities</span>
    <span class="n">total_frequency</span> <span class="o">=</span> <span class="n">lexicon_df</span><span class="p">[</span><span class="s1">&#39;lfrq&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    
    <span class="c1"># now we divide the lfrq values by total_frequency</span>
    <span class="c1"># we go ahead and do it in word_prob_dict because it has local scope -- we </span>
    <span class="c1"># are not changing the lexicon outside the function, just the &#39;copy&#39; we have</span>
    <span class="c1"># inside the function (could make a version of this outside the function and</span>
    <span class="c1"># pass it inside and then skip this normalization step...)</span>
    <span class="n">word_prob_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;Item&#39;</span><span class="p">]:</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;lfrq&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">total_frequency</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">lexicon_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()}</span>

    <span class="c1"># Print the elapsed time -- just keeping user updated, and trying to figure</span>
    <span class="c1"># out how long each part is taking</span>
    <span class="c1"># part2 = time.time()</span>
    <span class="c1"># elapsed_time = part2 - part1</span>
    <span class="c1"># print(f&quot;  Part 1b: {elapsed_time:.6f} seconds&quot;)</span>

    <span class="c1"># Print the elapsed time from start_time so far</span>
    <span class="c1"># elapsed_time = time.time() - start_time</span>
    <span class="c1"># print(f&quot;  Times so far: {elapsed_time:.6f} seconds&quot;)</span>

    <span class="c1"># Loop through each phoneme in the target word</span>
    <span class="k">for</span> <span class="n">phoneme_pos</span><span class="p">,</span> <span class="n">phoneme</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target_phonemes</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">phon_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Step 1: Get the bottom-up probability for the phoneme</span>
        <span class="n">phoneme_prob_at_pos</span> <span class="o">=</span> <span class="n">get_phoneme_prob_at_position</span><span class="p">(</span><span class="n">phoneme</span><span class="p">,</span> <span class="n">normalized_cosine_sim_df</span><span class="p">,</span> <span class="n">phoneme_prob_dict</span><span class="p">)</span>
        
        <span class="c1"># Store the phoneme probabilities in the new list</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">phoneme_prob_at_pos</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">phoneme_prob_list</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;Phoneme Position&#39;</span><span class="p">:</span> <span class="n">phoneme_pos</span><span class="p">,</span> <span class="s1">&#39;Phoneme&#39;</span><span class="p">:</span> <span class="n">p</span><span class="p">,</span> <span class="s1">&#39;Probability&#39;</span><span class="p">:</span> <span class="n">prob</span><span class="p">})</span>
            <span class="c1"># for debugging / inspection -- uncomment next line to see the phoneme probabilities at </span>
            <span class="c1"># each phoneme_pos</span>
            <span class="c1">#print(f&#39;     ##### Phoneme Position {phoneme_pos}, Phoneme {p}, Probability {prob}&#39;)</span>

        <span class="c1"># Step 2: Calculate the probability of each word&#39;s substrings (pseq)</span>
        <span class="n">updated_prob_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">word_pronunciation</span> <span class="ow">in</span> <span class="n">lexicon_df</span><span class="p">[[</span><span class="s1">&#39;Item&#39;</span><span class="p">,</span> <span class="s1">&#39;Pronunciation&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="p">:</span>
            <span class="n">word_phonemes</span> <span class="o">=</span> <span class="n">word_pronunciation</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
            
            <span class="c1"># this is brute force way to deal with words that are shorter than </span>
            <span class="c1"># the current word -- we just ignore them once the input is longer </span>
            <span class="c1"># than their length... Maybe this is not the best idea? To look at</span>
            <span class="c1"># later... </span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_phonemes</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">phoneme_pos</span><span class="p">:</span>
                <span class="k">continue</span>
            
            <span class="c1"># now we want pseq to be the product of the phoneme probabilities </span>
            <span class="c1"># for the current word at each position. We set it to 1.0 initially</span>
            <span class="c1"># so we can multiply it by the probabilities... This is the likelihood</span>
            <span class="c1"># step: ğ¿ğ‘–ğ‘˜ğ‘’ğ‘™ğ‘–â„ğ‘œğ‘œğ‘‘(ğ‘Šğ‘œğ‘Ÿğ‘‘ğ‘–)=ğ‘ƒ(ğ¸ğ‘£ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘ğ‘’|ğ‘Šğ‘œğ‘Ÿğ‘‘ğ‘–)=ğ‘ƒ(ğ‘ƒâ„ğ‘œğ‘›ğ‘’ğ‘šğ‘’ğ‘†ğ‘¡ğ‘Ÿğ‘–ğ‘›ğ‘”ğ‘–)=âˆğ‘—=1ğ‘™ğ‘ƒ(ğ‘ƒâ„ğ‘œğ‘›ğ‘’ğ‘šğ‘’ğ‘—|ğ¸ğ‘£ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘ğ‘’)</span>
            <span class="n">pseq</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">phoneme_pos</span><span class="p">):</span>
                <span class="n">pseq</span> <span class="o">*=</span> <span class="n">phoneme_prob_at_pos</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word_phonemes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
                
            <span class="c1"># Step 3: Multiply by word probability and update</span>
            <span class="c1"># We take the pseq product and multiply by the word&#39;s probability</span>
            <span class="c1"># this is the step of ğ‘ƒ(ğ¸ğ‘£ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘ğ‘’|ğ‘Šğ‘œğ‘Ÿğ‘‘ğ‘–)Ã—ğ‘ƒ(ğ‘Šğ‘œğ‘Ÿğ‘‘ğ‘–) for ğ‘Šğ‘œğ‘Ÿğ‘‘ğ‘–</span>
            <span class="n">updated_prob_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">pseq</span> <span class="o">*</span> <span class="n">word_prob_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        
        <span class="c1"># Diagnostic prints for phoneme position 1</span>
        <span class="c1"># if phoneme_pos == 1:</span>
        <span class="n">prob_values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">updated_prob_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="c1"># print(f&quot;Statistics before normalization at phoneme {phoneme_pos}:&quot;)</span>
        <span class="c1"># print(f&quot;  Max: {max(prob_values):.15f}&quot;)</span>
        <span class="c1"># print(f&quot;  Min: {min(prob_values):.15f}&quot;)</span>
        <span class="c1"># print(f&quot;  Mean: {sum(prob_values) / len(prob_values):.15f}&quot;)</span>
        <span class="c1"># print(f&quot;  Std: {sum((x - sum(prob_values) / len(prob_values))**2 for x in prob_values)**0.5 / len(prob_values):.15f}&quot;)</span>

        <span class="c1"># Sort by probability and take only top X words</span>
        <span class="n">sorted_words</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">updated_prob_dict</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">topX</span><span class="p">]</span>
        <span class="c1"># Always include the target_word</span>
        <span class="k">if</span> <span class="n">target_word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">sorted_words</span><span class="p">]:</span>
            <span class="n">sorted_words</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">target_word</span><span class="p">,</span> <span class="n">updated_prob_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">target_word</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>

        <span class="n">total_prob</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">prob</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">sorted_words</span><span class="p">])</span>
        
        <span class="c1"># Normalize only top X words</span>
        <span class="n">updated_prob_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">prob</span> <span class="o">/</span> <span class="n">total_prob</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">sorted_words</span><span class="p">}</span>

        <span class="c1"># Update lexicon to only include these top X words for the next phoneme</span>
        <span class="n">lexicon_df</span> <span class="o">=</span> <span class="n">lexicon_df</span><span class="p">[</span><span class="n">lexicon_df</span><span class="p">[</span><span class="s1">&#39;Item&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">sorted_words</span><span class="p">])]</span>
        
        <span class="c1"># Normalize the updated probabilities</span>
        <span class="n">total_prob</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">updated_prob_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">updated_prob_dict</span><span class="p">:</span>
            <span class="n">updated_prob_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">/=</span> <span class="n">total_prob</span>
        
        <span class="c1"># Diagnostic prints for phoneme position 1</span>
        <span class="c1"># if phoneme_pos == 1:</span>
        <span class="c1"># prob_values = list(updated_prob_dict.values())</span>
        <span class="c1"># print(f&quot;Statistics POST normalization at phoneme {phoneme_pos}:&quot;)</span>
        <span class="c1"># print(f&quot;  Max: {max(prob_values):.15f}&quot;)</span>
        <span class="c1"># print(f&quot;  Min: {min(prob_values):.15f}&quot;)</span>
        <span class="c1"># print(f&quot;  Mean: {sum(prob_values) / len(prob_values):.15f}&quot;)</span>
        <span class="c1"># print(f&quot;  Std: {sum((x - sum(prob_values) / len(prob_values))**2 for x in prob_values)**0.5 / len(prob_values):.15f}&quot;)</span>

        <span class="c1"># Update word_prob_dict for next iteration</span>
        <span class="n">word_prob_dict</span> <span class="o">=</span> <span class="n">updated_prob_dict</span>
        
        <span class="c1"># Create a DataFrame for this phoneme position and append to the result list</span>
        <span class="n">temp_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">word_prob_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Item&#39;</span><span class="p">,</span> <span class="s1">&#39;Probability&#39;</span><span class="p">])</span>
        <span class="n">temp_df</span> <span class="o">=</span> <span class="n">temp_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;Probability&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">temp_df</span><span class="p">[</span><span class="s1">&#39;Phoneme Position&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">phoneme_pos</span>
        <span class="n">result_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp_df</span><span class="p">)</span>
        
        <span class="c1"># Print the elapsed time for this phoneme</span>
        <span class="c1"># elapsed_time = time.time() - phon_start</span>
        <span class="c1"># print(f&quot;      Time elapsed after processing phoneme {phoneme_pos}: {elapsed_time:.6f} seconds&quot;)        </span>
        
    <span class="c1"># New DataFrame for phoneme probabilities</span>
    <span class="n">posterior_phon_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">phoneme_prob_list</span><span class="p">)</span>
    
    <span class="c1"># Combine all the DataFrames into one and return </span>
    <span class="c1"># [ignore_index=True speeds things by disregarding existing index values]</span>
    <span class="n">result_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">result_list</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Calculate peak activations for each word</span>
    <span class="n">peak_activations</span> <span class="o">=</span> <span class="n">result_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Item&#39;</span><span class="p">)[</span><span class="s1">&#39;Probability&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
    
    <span class="c1"># Select the target topX words by peak activation</span>
    <span class="n">top_words</span> <span class="o">=</span> <span class="n">peak_activations</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">topX</span><span class="p">)</span>
    
    <span class="c1"># Filter final results to only include these top words</span>
    <span class="n">posterior_word_df</span> <span class="o">=</span> <span class="n">result_df</span><span class="p">[</span><span class="n">result_df</span><span class="p">[</span><span class="s1">&#39;Item&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">top_words</span><span class="p">[</span><span class="s1">&#39;Item&#39;</span><span class="p">])]</span>
    
    <span class="c1"># Create an ordered list of words based on peak activations</span>
    <span class="n">sorted_words_by_peak</span> <span class="o">=</span> <span class="n">top_words</span><span class="p">[</span><span class="s1">&#39;Item&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="c1"># Move the target word to the top of the list</span>
    <span class="n">sorted_words_by_peak</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">target_word</span><span class="p">)</span>
    <span class="n">sorted_words_by_peak</span> <span class="o">=</span> <span class="p">[</span><span class="n">target_word</span><span class="p">]</span> <span class="o">+</span> <span class="n">sorted_words_by_peak</span>
    
    <span class="c1"># Create a dictionary to map each word to its index in sorted_words_by_peak, formatted as a string</span>
    <span class="n">sort_order</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">index</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sorted_words_by_peak</span><span class="p">)}</span>
    
    <span class="c1"># Add a new column that indicates the sort order based on peak activations</span>
    <span class="n">posterior_word_df</span> <span class="o">=</span> <span class="n">posterior_word_df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">posterior_word_df</span><span class="p">[</span><span class="s1">&#39;ItemWithOrder&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">posterior_word_df</span><span class="p">[</span><span class="s1">&#39;Item&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sort_order</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;99&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Add a target_word column to the final result DataFrames; could help with subsequent analysis</span>
    <span class="n">posterior_word_df</span><span class="p">[</span><span class="s1">&#39;Target Word&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">target_word</span>
    <span class="n">posterior_phon_df</span><span class="p">[</span><span class="s1">&#39;Target Word&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">target_word</span>
     
    <span class="c1"># Print the total elapsed time</span>
    <span class="n">total_elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">... Time for simulation: </span><span class="si">{</span><span class="n">total_elapsed_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">posterior_word_df</span><span class="p">,</span> <span class="n">posterior_phon_df</span>  <span class="c1"># Return both DataFrames</span>


<span class="k">def</span> <span class="nf">plot_simulation_result</span><span class="p">(</span><span class="n">word_result</span><span class="p">,</span> <span class="n">phon_result</span><span class="p">,</span> <span class="n">log_scale</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">full_scale</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">saveplots</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">phonplot</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">wordplot</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots a line graph based on the simulation result DataFrame and phoneme probabilities.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">        word_result (DataFrame): The DataFrame containing simulation results.</span>
<span class="sd">        phon_result (DataFrame): The DataFrame containing phoneme probabilities.</span>
<span class="sd">        log_scale (bool): Whether to use a log scale for the Y-axis. Default is False.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">unique_words</span> <span class="o">=</span> <span class="n">word_result</span><span class="p">[</span><span class="s1">&#39;Target Word&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">unique_words</span><span class="p">:</span>
        <span class="c1"># Filter data for the current word</span>
        <span class="n">word_data</span> <span class="o">=</span> <span class="n">word_result</span><span class="p">[</span><span class="n">word_result</span><span class="p">[</span><span class="s1">&#39;Target Word&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">word</span><span class="p">]</span>
        <span class="n">phon_data</span> <span class="o">=</span> <span class="n">phon_result</span><span class="p">[</span><span class="n">phon_result</span><span class="p">[</span><span class="s1">&#39;Target Word&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">word</span><span class="p">]</span>
        
        <span class="n">marker_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;.&quot;</span><span class="p">,</span><span class="s2">&quot;o&quot;</span><span class="p">,</span><span class="s2">&quot;v&quot;</span><span class="p">,</span><span class="s2">&quot;^&quot;</span><span class="p">,</span><span class="s2">&quot;&lt;&quot;</span><span class="p">,</span><span class="s2">&quot;&gt;&quot;</span><span class="p">,</span><span class="s2">&quot;1&quot;</span><span class="p">,</span><span class="s2">&quot;2&quot;</span><span class="p">,</span><span class="s2">&quot;3&quot;</span><span class="p">,</span><span class="s2">&quot;4&quot;</span><span class="p">,</span><span class="s2">&quot;8&quot;</span><span class="p">,</span><span class="s2">&quot;s&quot;</span><span class="p">,</span><span class="s2">&quot;p&quot;</span><span class="p">,</span><span class="s2">&quot;P&quot;</span><span class="p">,</span><span class="s2">&quot;*&quot;</span><span class="p">,</span><span class="s2">&quot;h&quot;</span><span class="p">,</span><span class="s2">&quot;H&quot;</span><span class="p">,</span><span class="s2">&quot;+&quot;</span><span class="p">,</span><span class="s2">&quot;x&quot;</span><span class="p">,</span><span class="s2">&quot;X&quot;</span><span class="p">,</span><span class="s2">&quot;D&quot;</span><span class="p">,</span><span class="s2">&quot;d&quot;</span><span class="p">,</span><span class="s2">&quot;|&quot;</span><span class="p">,</span><span class="s2">&quot;_&quot;</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">]</span>
        <span class="n">marker_iter</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">cycle</span><span class="p">(</span><span class="n">marker_list</span><span class="p">)</span>
        
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
        
        <span class="c1"># Initialize empty lists for legend labels and handles</span>
        <span class="n">word_legend_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">word_legend_handles</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># First subplot for word probabilities</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">word_data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;ItemWithOrder&#39;</span><span class="p">):</span>
            <span class="n">marker</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">marker_iter</span><span class="p">)</span>
            <span class="n">line</span><span class="p">,</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;Phoneme Position&#39;</span><span class="p">],</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;Probability&#39;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
            <span class="n">word_legend_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="n">word_legend_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
        
        <span class="c1"># the wordplot arguments limit the lists to that many items in the legend, even if more lines plot</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">word_legend_handles</span><span class="p">[:</span><span class="n">wordplot</span><span class="p">],</span> <span class="n">word_legend_labels</span><span class="p">[:</span><span class="n">wordplot</span><span class="p">])</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Phoneme Position&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Word probabilities for </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">word_data</span><span class="p">[</span><span class="s1">&#39;Phoneme Position&#39;</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">word_data</span><span class="p">[</span><span class="s1">&#39;Phoneme Position&#39;</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
        
        <span class="c1"># Calculate peak activations for each phoneme</span>
        <span class="n">peak_phoneme_activations</span> <span class="o">=</span> <span class="n">phon_data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Phoneme&#39;</span><span class="p">)[</span><span class="s1">&#39;Probability&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
        
        <span class="c1"># Select the topphon phonemes by peak activation</span>
        <span class="n">top_phonemes</span> <span class="o">=</span> <span class="n">peak_phoneme_activations</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">phonplot</span><span class="p">)[</span><span class="s1">&#39;Phoneme&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="c1">#print(top_phonemes)</span>
        
        <span class="c1"># Initialize empty lists for legend labels and handles</span>
        <span class="n">phoneme_legend_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">phoneme_legend_handles</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Second subplot for phoneme probabilities</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">phon_data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Phoneme&#39;</span><span class="p">):</span>
            <span class="n">marker</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">marker_iter</span><span class="p">)</span>
            <span class="n">line</span><span class="p">,</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s1">&#39;Phoneme Position&#39;</span><span class="p">],</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;Probability&#39;</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
            <span class="c1"># Only add to the legend if the phoneme is among the topphon</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">top_phonemes</span><span class="p">:</span>
                <span class="n">phoneme_legend_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                <span class="n">phoneme_legend_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>        
                
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">phoneme_legend_handles</span><span class="p">[:</span><span class="n">phonplot</span><span class="p">],</span> <span class="n">phoneme_legend_labels</span><span class="p">[:</span><span class="n">phonplot</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Phonemes&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Phoneme Position&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Phoneme Probabilities for </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">phon_data</span><span class="p">[</span><span class="s1">&#39;Phoneme Position&#39;</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">phon_data</span><span class="p">[</span><span class="s1">&#39;Phoneme Position&#39;</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
        
        <span class="k">if</span> <span class="n">log_scale</span><span class="p">:</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="c1">#full_scale = True</span>
        <span class="c1"># If full_scale is True, set the y-axis to range from 0 to 1</span>
        <span class="k">if</span> <span class="n">full_scale</span><span class="p">:</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        
        <span class="k">if</span> <span class="n">saveplots</span><span class="p">:</span>
            <span class="c1"># Ensure the directory exists</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;plots&#39;</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s1">&#39;plots&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;plots/</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s1">.png&#39;</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">run_simulations</span><span class="p">(</span><span class="n">word_list</span><span class="p">,</span> <span class="n">lexicon_df</span><span class="p">,</span> <span class="n">normalized_cosine_sim_df</span><span class="p">,</span> <span class="n">phoneme_prob_dict</span><span class="p">,</span> <span class="n">topX</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs simulations for a list of words and returns aggregated results.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">        word_list (list): List of words to simulate.</span>
<span class="sd">        lexicon_df (DataFrame): The DataFrame containing the lexicon.</span>
<span class="sd">        normalized_cosine_sim_df (DataFrame): The DataFrame containing normalized cosine similarities.</span>
<span class="sd">        phoneme_prob_dict (dict): Dictionary containing the probabilities of each phoneme.</span>
<span class="sd">        topX (int): Number of top words to consider during simulation. Default is 50.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        DataFrame, DataFrame: Aggregated word and phoneme results.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Initialize empty DataFrames to store aggregated results</span>
    <span class="n">aggregated_word_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">aggregated_phoneme_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_list</span><span class="p">:</span>
        <span class="c1">#print(f&quot;--- Running simulation for word: {word}&quot;)</span>
        <span class="n">word_result</span><span class="p">,</span> <span class="n">phon_result</span> <span class="o">=</span> <span class="n">sim_bayes_new</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">lexicon_df</span><span class="p">,</span> <span class="n">normalized_cosine_sim_df</span><span class="p">,</span> <span class="n">phoneme_prob_dict</span><span class="p">,</span> <span class="n">topX</span><span class="p">)</span>
        
        <span class="c1"># Append the results to the aggregated DataFrames</span>
        <span class="n">aggregated_word_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">aggregated_word_results</span><span class="p">,</span> <span class="n">word_result</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">aggregated_phoneme_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">aggregated_phoneme_results</span><span class="p">,</span> <span class="n">phon_result</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">aggregated_word_results</span><span class="p">,</span> <span class="n">aggregated_phoneme_results</span>


<span class="c1"># Function to read in the lexicon file</span>
<span class="k">def</span> <span class="nf">read_lexicon_file</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
    <span class="n">lexicon_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lexicon_df</span>

<span class="c1"># Read the lexicon file</span>
<span class="n">lexicon_df</span> <span class="o">=</span> <span class="n">read_lexicon_file</span><span class="p">(</span><span class="s1">&#39;./lemmalex.csv&#39;</span><span class="p">)</span>

<span class="c1"># Drop any rows with NaN [not a number, here indicating no value] available</span>
<span class="c1"># values in the &#39;Pronunciation&#39; column</span>
<span class="n">lexicon_df</span> <span class="o">=</span> <span class="n">lexicon_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Pronunciation&#39;</span><span class="p">])</span>

<span class="c1"># add log frequency column</span>
<span class="n">lexicon_df</span><span class="p">[</span><span class="s1">&#39;lfrq&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lexicon_df</span><span class="p">[</span><span class="s1">&#39;Frequency&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># lexicon_df.head()</span>

<span class="c1"># Calculate mean and standard deviation of &#39;lfrq&#39;</span>
<span class="n">mean_lfrq</span> <span class="o">=</span> <span class="n">lexicon_df</span><span class="p">[</span><span class="s1">&#39;lfrq&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">std_lfrq</span> <span class="o">=</span> <span class="n">lexicon_df</span><span class="p">[</span><span class="s1">&#39;lfrq&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="c1"># Define the boundaries for acceptable &#39;lfrq&#39; values</span>
<span class="n">lower_bound</span> <span class="o">=</span> <span class="n">mean_lfrq</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">std_lfrq</span>
<span class="n">upper_bound</span> <span class="o">=</span> <span class="n">mean_lfrq</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">std_lfrq</span>

<span class="c1"># Remove records where &#39;lfrq&#39; is more than 3 standard deviations from the mean</span>
<span class="n">filtered_lexicon_df</span> <span class="o">=</span> <span class="n">lexicon_df</span><span class="p">[(</span><span class="n">lexicon_df</span><span class="p">[</span><span class="s1">&#39;lfrq&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">lower_bound</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">lexicon_df</span><span class="p">[</span><span class="s1">&#39;lfrq&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">upper_bound</span><span class="p">)]</span>
<span class="c1"># let&#39;s just replace lexicon_df with the filtered one</span>
<span class="n">lexicon_df</span> <span class="o">=</span> <span class="n">filtered_lexicon_df</span>


<span class="c1"># Extract unique phonemes</span>
<span class="n">unique_phonemes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">for</span> <span class="n">pronunciation</span> <span class="ow">in</span> <span class="n">lexicon_df</span><span class="p">[</span><span class="s1">&#39;Pronunciation&#39;</span><span class="p">]:</span>
    <span class="n">phonemes</span> <span class="o">=</span> <span class="n">pronunciation</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">unique_phonemes</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">phonemes</span><span class="p">)</span>
<span class="n">sorted_unique_phonemes</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">unique_phonemes</span><span class="p">))</span>
<span class="n">num_phonemes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_unique_phonemes</span><span class="p">)</span>
<span class="n">phoneme_to_index</span> <span class="o">=</span> <span class="p">{</span><span class="n">phoneme</span><span class="p">:</span> <span class="n">index</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">phoneme</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sorted_unique_phonemes</span><span class="p">)}</span>

<span class="c1"># Create a weighted matrix for phoneme pairs</span>
<span class="n">weighted_phoneme_matrix_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="c1"># create dictionary for frequency-weighted counts of each phoneme</span>
<span class="n">phoneme_count_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>


<span class="c1"># Now let&#39;s fill the matrix</span>
<span class="n">fweight</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># how much to use frequency; when set to 1, just use full value</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">lexicon_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">pronunciation</span><span class="p">,</span> <span class="n">lfrq</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;Pronunciation&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;lfrq&#39;</span><span class="p">]</span>
    <span class="n">phonemes</span> <span class="o">=</span> <span class="n">pronunciation</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    
    <span class="c1"># Update the frequency-weighted count for each individual phoneme</span>
    <span class="k">for</span> <span class="n">phoneme</span> <span class="ow">in</span> <span class="n">phonemes</span><span class="p">:</span>
        <span class="n">phoneme_count_dict</span><span class="p">[</span><span class="n">phoneme</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">lfrq</span> <span class="o">*</span> <span class="n">fweight</span><span class="p">)</span>
 
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">phonemes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">first_phoneme</span><span class="p">,</span> <span class="n">second_phoneme</span> <span class="o">=</span> <span class="n">phonemes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">phonemes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">weighted_phoneme_matrix_dict</span><span class="p">[(</span><span class="n">first_phoneme</span><span class="p">,</span> <span class="n">second_phoneme</span><span class="p">)]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">lfrq</span> <span class="o">*</span> <span class="n">fweight</span><span class="p">)</span>
        <span class="n">weighted_phoneme_matrix_dict</span><span class="p">[(</span><span class="n">second_phoneme</span><span class="p">,</span> <span class="n">first_phoneme</span><span class="p">)]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">lfrq</span> <span class="o">*</span> <span class="n">fweight</span><span class="p">)</span>


<span class="c1"># Initialize the weighted matrix</span>
<span class="n">weighted_phoneme_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_phonemes</span><span class="p">,</span> <span class="n">num_phonemes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="k">for</span> <span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">second</span><span class="p">),</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">weighted_phoneme_matrix_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">phoneme_to_index</span><span class="p">[</span><span class="n">first</span><span class="p">],</span> <span class="n">phoneme_to_index</span><span class="p">[</span><span class="n">second</span><span class="p">]</span>
    <span class="n">weighted_phoneme_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span>

<span class="c1"># Convert the matrix to a DataFrame for better readability</span>
<span class="n">weighted_phoneme_matrix_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">weighted_phoneme_matrix</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">sorted_unique_phonemes</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">sorted_unique_phonemes</span><span class="p">)</span>

<span class="c1"># Convert the phoneme_count_dict to a DataFrame for better readability</span>
<span class="n">phoneme_count_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">phoneme_count_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Phoneme&#39;</span><span class="p">,</span> <span class="s1">&#39;FrequencyWeightedCount&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;FrequencyWeightedCount&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Calculate the sum of all FrequencyWeightedCount values</span>
<span class="n">total_count</span> <span class="o">=</span> <span class="n">phoneme_count_df</span><span class="p">[</span><span class="s1">&#39;FrequencyWeightedCount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1"># Add a new column for normalized probabilities</span>
<span class="n">phoneme_count_df</span><span class="p">[</span><span class="s1">&#39;phon_prob&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">phoneme_count_df</span><span class="p">[</span><span class="s1">&#39;FrequencyWeightedCount&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">total_count</span>

<span class="c1"># Create a simpler dictionary that just pairs phonemes with their normalized probabilities (phon_prob)</span>
<span class="n">phoneme_prob_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">phoneme_count_df</span><span class="p">[</span><span class="s1">&#39;Phoneme&#39;</span><span class="p">],</span> <span class="n">phoneme_count_df</span><span class="p">[</span><span class="s1">&#39;phon_prob&#39;</span><span class="p">]))</span>
<span class="n">phoneme_prob_dict</span>

<span class="c1"># Display a portion of the weighted matrix and phoneme count matrix for review</span>
<span class="n">weighted_phoneme_matrix_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">],</span> <span class="n">phoneme_prob_dict</span><span class="c1">#,phoneme_count_df.iloc[:100, :10]</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="c1"># Compute the cosine similarity between each pair of phoneme vectors</span>
<span class="n">cosine_sim_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">weighted_phoneme_matrix</span><span class="p">)</span>

<span class="c1"># Convert the similarity matrix to a DataFrame for better readability</span>
<span class="n">cosine_sim_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cosine_sim_matrix</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">sorted_unique_phonemes</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">sorted_unique_phonemes</span><span class="p">)</span>

<span class="c1"># Display a portion of the cosine similarity matrix</span>
<span class="n">cosine_sim_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">,</span> <span class="p">:</span><span class="mi">10</span><span class="p">]</span>
<span class="c1"># Reduce the off-diagonal entries -- divide by 5 for now</span>
<span class="n">off_diagonal_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">cosine_sim_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">))</span>
<span class="n">adjusted_cosine_sim_matrix</span> <span class="o">=</span> <span class="n">cosine_sim_matrix</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">adjusted_cosine_sim_matrix</span><span class="p">[</span><span class="n">off_diagonal_indices</span><span class="p">]</span> <span class="o">/=</span> <span class="mf">5.0</span>

<span class="c1"># Convert the adjusted similarity matrix to a DataFrame for better readability</span>
<span class="n">adjusted_cosine_sim_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">adjusted_cosine_sim_matrix</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">sorted_unique_phonemes</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">sorted_unique_phonemes</span><span class="p">)</span>

<span class="c1"># Display a portion of the adjusted cosine similarity matrix</span>
<span class="n">adjusted_cosine_sim_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">,</span> <span class="p">:</span><span class="mi">10</span><span class="p">]</span>



<span class="c1"># Normalize the rows of the adjusted cosine similarity matrix so they sum to 1</span>
<span class="n">row_sums</span> <span class="o">=</span> <span class="n">adjusted_cosine_sim_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">normalized_cosine_sim_matrix</span> <span class="o">=</span> <span class="n">adjusted_cosine_sim_matrix</span> <span class="o">/</span> <span class="n">row_sums</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

<span class="c1"># Convert the normalized similarity matrix to a DataFrame for better readability</span>
<span class="n">normalized_cosine_sim_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">normalized_cosine_sim_matrix</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">sorted_unique_phonemes</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">sorted_unique_phonemes</span><span class="p">)</span>

<span class="c1"># Display a portion of the normalized cosine similarity matrix</span>
<span class="n">normalized_cosine_sim_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">,</span> <span class="p">:</span><span class="mi">10</span><span class="p">]</span>








<span class="c1"># Example usage:</span>
<span class="n">word_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;abrupt&#39;</span><span class="p">,</span> <span class="s1">&#39;territory&#39;</span><span class="p">,</span> <span class="s1">&#39;abandon&#39;</span><span class="p">,</span> <span class="s1">&#39;clamp&#39;</span><span class="p">,</span> <span class="s1">&#39;intolerable&#39;</span><span class="p">,</span> <span class="s1">&#39;sew&#39;</span><span class="p">]</span>
<span class="n">aggregated_word_results</span><span class="p">,</span> <span class="n">aggregated_phoneme_results</span> <span class="o">=</span> <span class="n">run_simulations</span><span class="p">(</span><span class="n">word_list</span><span class="p">,</span> <span class="n">lexicon_df</span><span class="p">,</span> 
                                                                      <span class="n">normalized_cosine_sim_df</span><span class="p">,</span> <span class="n">phoneme_prob_dict</span><span class="p">)</span>
<span class="n">plot_simulation_result</span><span class="p">(</span><span class="n">aggregated_word_results</span><span class="p">,</span> <span class="n">aggregated_phoneme_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Starting simulation of word cat	... Time for simulation: 0.241187 seconds
--- Starting simulation of word dog	... Time for simulation: 0.253156 seconds
--- Starting simulation of word abrupt	... Time for simulation: 0.269662 seconds
--- Starting simulation of word territory	... Time for simulation: 0.258804 seconds
--- Starting simulation of word abandon	... Time for simulation: 0.304343 seconds
--- Starting simulation of word clamp	... Time for simulation: 0.252167 seconds
--- Starting simulation of word intolerable	... Time for simulation: 0.254806 seconds
--- Starting simulation of word sew	... Time for simulation: 0.243537 seconds
</pre></div>
</div>
<img alt="_images/bba91cb2acc3da8866206c2a6b5c972f97b766eb9aa55cde4476f8ae96a04c06.png" src="_images/bba91cb2acc3da8866206c2a6b5c972f97b766eb9aa55cde4476f8ae96a04c06.png" />
<img alt="_images/d87a110942c33d6410910ccb2bdf28d1499933917a377592759ededc46bcf203.png" src="_images/d87a110942c33d6410910ccb2bdf28d1499933917a377592759ededc46bcf203.png" />
<img alt="_images/22652f262a3acf80a8b077f1b853f907645d41e060ddcf7077379294c674df8c.png" src="_images/22652f262a3acf80a8b077f1b853f907645d41e060ddcf7077379294c674df8c.png" />
<img alt="_images/04b6e7735c1f41dbfd4c1981c51c73fea8dd610174443feb8c37e5220bd8b95e.png" src="_images/04b6e7735c1f41dbfd4c1981c51c73fea8dd610174443feb8c37e5220bd8b95e.png" />
<img alt="_images/419c26180b4f5b3b467ba2b3e5dc3c18ee0aa22b2b1a0be9c0d1765fd9d25caf.png" src="_images/419c26180b4f5b3b467ba2b3e5dc3c18ee0aa22b2b1a0be9c0d1765fd9d25caf.png" />
<img alt="_images/60db97640ebff16b6c53226856a0c6ea629329d4498bbd83e676c3deaf555968.png" src="_images/60db97640ebff16b6c53226856a0c6ea629329d4498bbd83e676c3deaf555968.png" />
<img alt="_images/b669ac01656379ed9f4550d393619433ddb24ba698e69c99b3069f4c0b77a627.png" src="_images/b669ac01656379ed9f4550d393619433ddb24ba698e69c99b3069f4c0b77a627.png" />
<img alt="_images/c3b4be80debe4ca98485ef1d7f2a87be39a77510b2cc4277d33c09858fda39a6.png" src="_images/c3b4be80debe4ca98485ef1d7f2a87be39a77510b2cc4277d33c09858fda39a6.png" />
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="simple visible nav section-nav flex-column">
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>